# ğŸ“š Book API â€“ Tech Challenge Fase 1

API REST construÃ­da com **FastAPI** para consulta de livros, obtidos via *web scraping* no site [Books to Scrape](https://books.toscrape.com).  
O projeto implementa endpoints para listagem de livros, busca por tÃ­tulo e categoria, listagem de categorias, verificaÃ§Ã£o de saÃºde da API e atualizaÃ§Ã£o dos dados via scraping.

---

## ğŸ— Arquitetura do Projeto

- **FastAPI** â€“ Framework backend para APIs rÃ¡pidas e tipadas.  
- **BeautifulSoup4** â€“ Biblioteca de *web scraping* para extraÃ§Ã£o de dados HTML.  
- **Pandas** â€“ ManipulaÃ§Ã£o e leitura de dados tabulares (CSV).  
- **Pydantic** â€“ ValidaÃ§Ã£o e tipagem dos dados de entrada/saÃ­da.  
- **Docker** â€“ ContainerizaÃ§Ã£o da aplicaÃ§Ã£o para fÃ¡cil deploy.  
- **Railway** â€“ Plataforma de deploy utilizada.

ğŸ“‚ Estrutura de pastas:
```
app/
 â”œâ”€â”€ api/
 â”‚   â””â”€â”€ v1/
 â”‚       â”œâ”€â”€ books.py        # Endpoints de livros
 â”‚       â”œâ”€â”€ categories.py   # Endpoints de categorias
 â”‚       â”œâ”€â”€ health.py       # Endpoint de status/healthcheck
 â”œâ”€â”€ core/
 â”‚   â””â”€â”€ config.py           # ConfiguraÃ§Ãµes da aplicaÃ§Ã£o
 â”œâ”€â”€ models/
 â”‚   â””â”€â”€ book.py             # Modelo Pydantic Book
 â”œâ”€â”€ services/
 â”‚   â”œâ”€â”€ scraper.py          # LÃ³gica de scraping
 â”œâ”€â”€ utils/
 â”‚   â””â”€â”€ scraper_utilitys.py # FunÃ§Ãµes auxiliares para scraping
 â”œâ”€â”€ main.py                 # Ponto de entrada da aplicaÃ§Ã£o
data/
 â””â”€â”€ books.csv               # Base de dados local
requirements.txt
Dockerfile
```

---

## âš™ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1ï¸âƒ£ Clonar o repositÃ³rio
```bash
git clone https://github.com/seuusuario/book-api.git
cd book-api
```

### 2ï¸âƒ£ Configurar variÃ¡veis de ambiente
Crie um arquivo `.env` (opcional, se quiser sobrescrever configs):
```env
CSV_PATH=./data/books.csv
BASE_URL=https://books.toscrape.com
```

### 3ï¸âƒ£ Rodar localmente (sem Docker)
```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
pip install -r requirements.txt
uvicorn app.main:app --reload
```

---

## ğŸ³ Executando com Docker

### Build da imagem
```bash
docker build -t book-api .
```

### Rodando o container
```bash
docker run -p 8000:8000 -v $(pwd)/data:/app/data book-api
```

Isso garante que o `books.csv` seja persistido localmente.

---

## ğŸ“– DocumentaÃ§Ã£o das Rotas

| MÃ©todo | Endpoint | DescriÃ§Ã£o |
|--------|----------|-----------|
| `GET` | `/` | Redireciona para o healthcheck |
| `GET` | `/api/v1/health` | Retorna status da API e integridade do CSV |
| `GET` | `/api/v1/books` | Lista todos os livros |
| `GET` | `/api/v1/books/search?title=...&category=...` | Busca por tÃ­tulo e/ou categoria |
| `GET` | `/api/v1/categories` | Lista categorias disponÃ­veis |
| `POST` | `/api/v1/scraping/trigger` | Executa o scraping e atualiza o CSV |

---

## ğŸ” Exemplos de Chamadas

### 1. Listar todos os livros
```bash
curl http://localhost:8000/api/v1/books
```
**Resposta**:
```json
{
  "titles": [
  "A Light in the Attic",
  "Tipping the Velvet",
  "Soumission",
  "Sharp Objects",
  "Sapiens: A Brief History of Humankind",
  "The Requiem Red"
  ]
}
```

### 2. Buscar por tÃ­tulo ou categoria
```bash
curl "http://localhost:8000/api/v1/books/search?title=A Light in the Attic"
```
**Resposta**:
```json
[
  {
    "id": 0,
    "title": "A Light in the Attic",
    "price": 51.77,
    "availability": "In stock",
    "rating": 3,
    "category": "Poetry",
    "image_url": "https://books.toscrape.com/media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg"
  }
]
```

### 3. Healthcheck
```bash
curl http://localhost:8000/api/v1/health
```
**Resposta**:
```json
{
  "api_status": "Online!",
  "csv_exists": true,
  "data_loaded": true,
  "has_required_columns": true
}
```

### 4. Rodar scraping manualmente
```bash
curl -X POST http://localhost:8000/api/v1/scraping/trigger
```

---

## â–¶ï¸ ExecuÃ§Ã£o no Railway

1. **Subir o projeto no GitHub**  
2. **Criar projeto no Railway** selecionando o repositÃ³rio  
3. Railway detecta o `Dockerfile` e realiza o build  
4. Adicionar variÃ¡vel:
   ```
   CSV_PATH=/app/data/books.csv
   ```
5. (Opcional) Criar **Volume** no Railway e montar em `/app/data` para persistÃªncia do CSV  
6. Testar a API acessando `https://<seu-projeto>.up.railway.app/docs`

---

## ğŸ“Œ ObservaÃ§Ãµes
- O CSV Ã© a fonte principal de dados; rodar o scraper sobrescreve/adiciona dados.
- Proteja a rota de scraping em produÃ§Ã£o para evitar abusos.
- O deploy no Railway Ã© feito diretamente com o Dockerfile (nÃ£o hÃ¡ uso de docker-compose).
